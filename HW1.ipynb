{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducrtion to Machine Learning: Assignment #1\n",
        "## Submission date: 01\\01\\2026, 23:59.\n",
        "### Topics:\n",
        "- Parametric Density Estimation\n",
        "- Bayesian Decision Rule\n",
        "- Linear regression\n",
        "- KNN\n",
        "- Naïve Bayes\n"
      ],
      "metadata": {
        "id": "WxQj_LVp7onx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submitted by:\n",
        "\n",
        " **Student 1 Name+ID\n",
        "\n",
        " **Student 2 Name+ID"
      ],
      "metadata": {
        "id": "Mih4qIYq7so3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment Instruction:**\n",
        "\n",
        "· Submissions in pairs only.\n",
        "\n",
        "· Try to keep the code as clean, concise, and short as possible\n",
        "\n",
        "· If you wish to work in your IDE, you can, but you **must**,  insert the script back to the matching cells of the notebook and run the code. <br/>Only the notebook will be submitted in moodle (in `.ipynb` format).\n",
        "\n",
        "· <font color='red'>Please write your answers to question in red</font>.\n",
        "\n",
        "**Important:** All plots, results and outputs should be included in the notebook as the cells' outputs (run all cells and do not clear the output). <br/>\n",
        "\n",
        "**Important:** Your submission must be entirely your own. Any attempts of plagiarism (including ChatGPT) will lead to grade 0 and disciplinary actions."
      ],
      "metadata": {
        "id": "D3nU_S097vG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 - Parametric Estimation and MAP"
      ],
      "metadata": {
        "id": "YSvfxRjjnk26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure to provide full solutions in a single PDF file.**"
      ],
      "metadata": {
        "id": "Rz52VPS_cXKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem, we are given n samples $\\{x_i \\}_{i=1}^n$, where each sample $x_i∈\\mathbb{N}^2$, meaning each sample has two features, which are non-negative integers. We aim to use these samples as a training set for a binary classification problem, where $\\mathcal{Y}=\\{0,1\\}$. It is known that both features in both classes follow a Poisson distribution, $(x^j│y=i)\\sim Pois(λ_i)$. Explicitly\n",
        "$$P(x^j│y=i)=\\frac{e^{-\\lambda_i}\\cdot\\lambda_i^{x^j}}{x^j!}$$\n",
        "\n",
        "In this question, assume a Naïve Bayes assumption on the samples within each class.\n",
        "\n",
        "1. Compute the probability $\\mathbb{P}(x=(5,3)|y=1)$ as function of $\\lambda_1$.\n",
        "2. Given $\\mathcal{D}=\\{((x_{i_1},x_{i_2}),y_i)\\}_{i=1}^n$, find the MLE for $\\lambda_i$.\n",
        "2. We are given the training set: $\\{{((2,4),1),((0,2),0)}\\}$. Assuming an equal prior for both classes. Determine the classification for the sample $x=(2,2)$."
      ],
      "metadata": {
        "id": "Fm9XHnvcntJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customizing Colab\n",
        "This is an optional section for you convenience:<br/>\n",
        "Go to Tools -> Settings -> editor<br/>\n",
        "There, you can adjust fonts, add line numbers, change indentations."
      ],
      "metadata": {
        "id": "gchhFra3MNHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 - Linear regression\n",
        "In this exercise you will implement linear regression alone!"
      ],
      "metadata": {
        "id": "GeVCGEMFSTD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset consists of a few 2-feature samples $\\{(x_i,y_i )\\}_{i=1}^∞$ where $y_i$ is the prediction of the $x_i\\in\\mathbb{R}^2$ sample. <br/>\n",
        "We will only try to fit the given data, <u>without validation or test</u>.<br/>\n",
        "We define the following:\n",
        "-\tX, 2d matrix from size n x d which represents the training samples.\n",
        "-\ty, array from size n which represents the target value for the corresponding sample.\n"
      ],
      "metadata": {
        "id": "R500wzm78Egr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libarires"
      ],
      "metadata": {
        "id": "peqJrR37SVQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jLPAazuoSUzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First visualization"
      ],
      "metadata": {
        "id": "x6A35INtXDwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    X = np.array([\n",
        "        [5.48, 7.15],\n",
        "        [6.02, 5.44],\n",
        "        [4.23, 6.45],\n",
        "        [4.37, 10.91],\n",
        "        [9.63, 3.83],\n",
        "        [7.91, 15.28],\n",
        "        [5.68, 12.25],\n",
        "        [0.71, 0.87],\n",
        "        [0.20, 11.32],\n",
        "        [7.78, 8.70]\n",
        "    ])\n",
        "    y = np.array([9.15, 11.87, 5.34, 8.91, 21.81, 17.23, 2.60, 4.27, -8.18, 11.41])\n",
        "    return X, y\n",
        "\n",
        "X, y = get_data()\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X[:,0], X[:,1], y, color='red')\n",
        "ax.set_xlabel('x1')\n",
        "ax.set_ylabel('x2')\n",
        "ax.set_zlabel('y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b7b0ahPkXDVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the function Linreg_sol(X,y) which outputs the closed form solution for linear regression on X,y. <br/>"
      ],
      "metadata": {
        "id": "wXZwduofSpNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X: (n,d) array\n",
        "# y: (n,) array\n",
        "# Output: (d,) array of weights\n",
        "\n",
        "def Linreg_sol(X, y):\n",
        "\t# Implement here"
      ],
      "metadata": {
        "id": "r9jo9K-fSnXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepear X and call the solver.<br/>\n",
        "Afterwards, print the MSE (this will be the training error)."
      ],
      "metadata": {
        "id": "p36_rpUXL1Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = # Implement here\n",
        "w = Linreg_sol(X, y)\n",
        "\n",
        "w1, w2, b = w\n",
        "\n",
        "print(f'The linear line is y={w1:.2f}*x1+{w2:.2f}*x2+{b:.2f}')\n",
        "\n",
        "y_pred = # Implement here\n",
        "mse =    # Implement here\n",
        "print(f'The MSE on the data is {mse:.2f}')"
      ],
      "metadata": {
        "id": "kMb5ULKjTE0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the line solution <br/>\n",
        "Does the line really fit the data? <br/>\n",
        "<font color='red'>Write here your answer and explain it</font>"
      ],
      "metadata": {
        "id": "qYqMQP_JcTb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepear a grid - many pairs of (x1,x2) to generate f(x1,x2) from\n",
        "x1_range = np.linspace(X[:,0].min(), X[:,0].max(), 30)\n",
        "x2_range = np.linspace(X[:,1].min(), X[:,1].max(), 30)\n",
        "x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
        "y_pred = w1 * x1_grid + w2 * x2_grid + b\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X[:,0], X[:,1], y, color='red', label='Data points')\n",
        "ax.plot_surface(x1_grid, x2_grid, y_pred, color='blue', alpha=0.5)\n",
        "ax.set_xlabel('x1')\n",
        "ax.set_ylabel('x2')\n",
        "ax.set_zlabel('y')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J7eSeWicVvCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above MSE should be much lower. Let's test a few techniques to deal with outliers and compare them."
      ],
      "metadata": {
        "id": "EBGKMKRpOdNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first technique is based upon the standard deviation:\n",
        "$$ s=\\sqrt{Var(SSE)}=\\sqrt{\\frac{\\sum_{i=1}^n (y_i-f(x_i))^2}{n-1}} $$\n",
        "\n",
        "Then, a point in the dataset defined as an outlier if its distance from the fitted line is more than two deviation s.<br/>\n",
        "Find and print the outliers from the dataset."
      ],
      "metadata": {
        "id": "zuct1cGNQ7ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = get_data()\n",
        "\n",
        "# Implement here and print the points that are outliers."
      ],
      "metadata": {
        "id": "zjFGiRVSQ6Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second technique is based upon quantiles. <br/>\n",
        "Run the following cell.\n",
        "- The yellow line is the median\n",
        "- The blue box shows the 25%-75% percentile\n",
        "- The lowest and highest lines in black show the lowest and highest values of the feature."
      ],
      "metadata": {
        "id": "KKwhXAiRR4no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = get_data()\n",
        "data = [X[:,0], X[:,1], y]\n",
        "labels = ['x1', 'x2', 'y']\n",
        "\n",
        "plt.boxplot(data, labels=labels, patch_artist=True)\n",
        "plt.title('Boxplots for each feature and target')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GjXtSZ_XSnRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, remove the bad percentile (upon your choice) and print the MSE on the modified data."
      ],
      "metadata": {
        "id": "7RD_R2JASwDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low, high = np.percentile(y, [l, h])    # replace l,h with your own values\n",
        "mask = (y >= low) & (y <= high)\n",
        "X_clean = X[mask]\n",
        "y_clean = y[mask]"
      ],
      "metadata": {
        "id": "vhrwj5KSS4Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following sum-up questions:\n",
        "1. Which method worked better? Why?\n",
        "2. Can you conclude something in general?\n",
        "<font color='red'>Write here your answers and explain them</font>"
      ],
      "metadata": {
        "id": "MSSKRjG2TGFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3 - Bayesian Decision Rule\n",
        "\n",
        "You are given a dataset represents customer behavior data collected from a retail company. The three classes represent different types of customers: infrequent buyers, occasional buyers, and frequent buyers. The features include 10 various customer features. <br/>\n",
        "Since the data is continuous, you will implement Gaussian bayes and compare to Gaussian naïve bayes.\n",
        "\n",
        "The dataset of customers is give by this url: https://sharon.srworkspace.com/ml/datasets/hw1/customers.csv"
      ],
      "metadata": {
        "id": "prp9oMrgRud7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libarires"
      ],
      "metadata": {
        "id": "OoYNLo6XIGlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "rGqprtZoIKoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use pandas module to load the dataset (directly from the url) into dataframe object.\n",
        "\n",
        "Print the table size and print the first 5 rows."
      ],
      "metadata": {
        "id": "uc_ziqtWIO6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "Amp-_NESRuBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As learned in the first tutorial, you should theoretically have a separate test set and craft a validation set from the data. However, we do not have such test and do not have any need from validation in this question.\n",
        "\n",
        "Convert the dataframe object to numpy matrix and split the data to 80% training and 20% test with random state of 42. <br/>Make sure to maintain the dataset priors, using stratify=y, in train_test_split method.\n",
        "<br/>Note that the dataframe object contains the labels as well."
      ],
      "metadata": {
        "id": "UKWn5AX9U1LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "chbDTlInILe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "A fundamental step in learning is to check our assumptions and apply fixes if required. You will do so now."
      ],
      "metadata": {
        "id": "NhrtVpKmGnzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to assume gaussian distribution, you need to check if most (or all) features are gaussian distributed.<br/>\n",
        "The code is attached below, but make sure it shows the features densities only.\n",
        "\n",
        "Well, are the features gaussian?"
      ],
      "metadata": {
        "id": "xTZYzDLvGyeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(kind='density', subplots=True, layout=(2, 5), figsize=(20, 6), sharex=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KhjjTrbUR4JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the correleation matrix of the <u>train data</u>. Hint: we have seen this in class. <br/>\n",
        "Print below the determinant of the covariance matrix\n",
        "\n",
        "What can you conclude about the data?<br/>\n",
        "<font color='red'>Write here your answer and explain</font>"
      ],
      "metadata": {
        "id": "zvLBYt1aIABE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "dm90izRgU66b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you got a problematic feature(s) and you decide to remove them - remove at most one feature. Make sure to adjust both train and test datasets.<br/>\n",
        "If not fix is required, leave the following code cell empty.\n",
        "\n",
        "If you continue to remove features, what do you expect to happend with the train error?<br/>\n",
        "<font color='red'>Write here your answer and explain</font>"
      ],
      "metadata": {
        "id": "qCLoHc1aNaj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "Yx-qmu100uHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing classification model"
      ],
      "metadata": {
        "id": "4AuGSwxD01pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the functions below. <br/>Both get train and test data $X\\in\\mathbb{R}^{n\\times d}$. <br/>\n",
        "Both return the predicted classes (vector sized n), but the naïve bayes assumes that the features are independent.\n",
        "\n",
        "**Warnings:**\n",
        "- Please use numpy for efficiency, as it will require only one loop. If you struggle, implement it as you know and optimize, step by step.\n",
        "- No helper functions are allowed here"
      ],
      "metadata": {
        "id": "fQ3PuGGEXVv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_point_gaussian_bayes(train, test):\n",
        "  # Implement here\n",
        "\n",
        "def classify_point_gaussian_naive_bayes(train, test):\n",
        "  # Implement here"
      ],
      "metadata": {
        "id": "Oj5jZiTWV7k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For both GB and GNB, we will look at train vs test. Run the next cell and answer the following:\n",
        "- Which model performed better? Why?\n",
        "- Could the other model be sometimes <u>better</u>? How, for example?\n",
        "\n",
        "<font color='red'>Write here your answers and explain</font>"
      ],
      "metadata": {
        "id": "Qo7NaPefNLIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder: success rate is the precentage of correctly classified data within the number of all data in the test set.\n",
        "\n",
        "dict1 = {'GB': [], 'GNB': []}\n",
        "\n",
        "accs = classify_point_gaussian_bayes(train=x_train, test=x_train)\n",
        "dict1['GB'].append(np.count_nonzero(accs == y_train) / len(y_train))\n",
        "\n",
        "accs = classify_point_gaussian_bayes(train=x_train, test=x_test)\n",
        "dict1['GB'].append(np.count_nonzero(accs == y_test) / len(y_test))\n",
        "\n",
        "accs = classify_point_gaussian_naive_bayes(train=x_train, test=x_train)\n",
        "dict1['GNB'].append(np.count_nonzero(accs == y_train) / len(y_train))\n",
        "\n",
        "accs = classify_point_gaussian_naive_bayes(train=x_train, test=x_test)\n",
        "dict1['GNB'].append(np.count_nonzero(accs == y_test) / len(y_test))\n",
        "\n",
        "df = pd.DataFrame(dict1, columns=['GB', 'GNB'], index=['train', 'test'])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "dXLQ4bS6NAP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sharon, help me!** when I tried to apply the gaussian bayes I got an error saying \"matrix is singular\" | \"invalid value encountered in log\".\n",
        "\n",
        "In theory, $\\Sigma$, the covariance matrix is proved (in lectures) being PSD (in particullary - positive determinant).\n",
        "\n",
        "However, practically, due to numerical stability it can have be small, yet negative determinant (for example, -2.383027111200437e-48). One great method for solving this issue, is instead of using $\\ln\\det\\Sigma_c$, using $\\ln(\\det\\Sigma_c+e^{-10})$.\n",
        "\n",
        "From $\\ln$ being increasing in $\\mathbb{R^+}$, it will not effect the relative classes scores."
      ],
      "metadata": {
        "id": "GJ93g5YvU3Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, lets visualize!\n",
        "\n",
        "Run the boundaries plotting for train and test with gaussian bayes.<br/>It will show the decision boundaries as saw in the lectures (do not modify it).\n",
        "\n",
        "Briefly explain the shape of the discriminant function in this case.\n",
        "\n",
        "<font color='red'>Write here your answer and explain</font>"
      ],
      "metadata": {
        "id": "FNr_1jPXN4J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Reduce the dimensionality of the data to 2 using PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit_transform(x_train)\n",
        "X_reduced = pca.transform(x_train)\n",
        "\n",
        "# Create a grid of points for visualization in the reduced 2D space\n",
        "x_min, x_max = X_reduced[:, 0].min() - 1, X_reduced[:, 0].max() + 1\n",
        "y_min, y_max = X_reduced[:, 1].min() - 1, X_reduced[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "# Use the GNB model to predict class labels for the grid points in the original 13D space\n",
        "grid_points = pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()])\n",
        "print(grid_points.shape)\n",
        "Z = classify_point_gaussian_naive_bayes(x_train, grid_points)\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundaries and the data points in the reduced 2D space\n",
        "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)\n",
        "scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y_train, cmap=plt.cm.RdYlBu, edgecolor='k', s=20)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "\n",
        "# Add a legend\n",
        "handles, labels = scatter.legend_elements()\n",
        "plt.legend(handles, labels, title='Classes')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dCjYD-nsoqRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For curios students - Why did we plotted two features only? How does this represent the dataset?\n",
        "\n",
        "Answer: well, you can't plot more than 3d and even there, it is terrible and not possible with contour in matplotlib. But - the method for extracting those two features is called PCA, and it gurantees to get the k most represntitive features. We will talk about it later on the course."
      ],
      "metadata": {
        "id": "MjpOuhdz6zkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4 - Naïve Bayes\n",
        "In this problem, you'll implement a basic Naïve Bayes classifier, and use it to predict the category for article news."
      ],
      "metadata": {
        "id": "8-sAUwri1Gwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will have to classify sentences into 5 categories, <b>but could be any number.</b><br/>\n",
        "The categories are {\"tech\", \"business\", \"sport\", \"entertainment\", \"politics\"}.\n",
        "\n",
        "<b>Warning:</b> I haven't personally looked through all the data here. Even though the data is taken from a popular ML databases site, please accept my apologies if there are any offensive sentences.\n"
      ],
      "metadata": {
        "id": "acuxlnhGm9BC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libarires"
      ],
      "metadata": {
        "id": "BuhWspAV1n-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "AtBhju1K1qXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the function. It reads all articles from file and returns the following data structures: <br/>\n",
        "•\ttexall - list of documents; each entry corresponds to an article which is an array of words. <br/>\n",
        "•\tlbAll list of articles' labels.<br/>\n",
        "•\tvoc - set of all distinct words in the entire data.<br/>\n",
        "•\tcat - set of article categories.\n"
      ],
      "metadata": {
        "id": "SwwN8oVTn-HO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readTrainData(file_name):\n",
        "  df = pd.read_csv(file_name)\n",
        "  # Implement here\n",
        "  return texAll, lbAll, voc, cat"
      ],
      "metadata": {
        "id": "_zZYY_brn9Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the function, which computes and returns the probabilities (on the train set):<br/>\n",
        "- $P_w$ - a matrix of class-conditional probabilities, $p(x|w_i)$\n",
        "- $P$ - a vector of class priors, $p(w_i)$\n",
        "\n",
        "Make sure you deal with the case of word that appears in voc but not in class $w$.\n",
        "\n",
        "Note: this function does not need any inputs, as the train (and test) are globaly defined below."
      ],
      "metadata": {
        "id": "6xUbLY2Tol7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def learn_NB_text():\n",
        "  # Implement here\n",
        "  return Pw, P"
      ],
      "metadata": {
        "id": "uYiXzZCIow9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement fhe function that classifies all articles from the test set and computes the success rate.<br/>\n",
        "Iterate over all articles of test and for each article find the most probable category.\n",
        "\n",
        "\n",
        "Note: Multiplying lots of probabilities, which are between 0 and 1, can result in floating-point underflow. Since log(xy) = log(x) + log(y), it is better to perform all computations by summing logs of probabilities rather than multiplying probabilities. <br/>Class with highest final un-normalized log probability score is still the most probable.\n"
      ],
      "metadata": {
        "id": "SkmMTneCpTm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ClassifyNB_text(Pw, P):\n",
        "\t# Implement here"
      ],
      "metadata": {
        "id": "-epXTXF5EHtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the files"
      ],
      "metadata": {
        "id": "LMZXLXTbp84V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_FILE = 'https://sharon.srworkspace.com/ml/datasets/hw1/bbc_train.csv'\n",
        "TEST_FILE = 'https://sharon.srworkspace.com/ml/datasets/hw1/bbc_test.csv'\n",
        "\n",
        "texAll_train, lblAll_train, voc, cat = readTrainData(TRAIN_FILE)\n",
        "\n",
        "# cats must be the same at train and test\n",
        "# voc of test is irrelevant - we already trained on other voc.\n",
        "texAll_test, lblAll_test, _, __ = readTrainData(TEST_FILE)"
      ],
      "metadata": {
        "id": "wZa-wSjvZK2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model, classify it on the test and report the success rate"
      ],
      "metadata": {
        "id": "m1ss4d_dqyk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pw, P = learn_NB_text()\n",
        "acc_right = ClassifyNB_text(Pw, P)\n",
        "print(acc_right)"
      ],
      "metadata": {
        "id": "u5_sN3V-GOah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5 - KNN\n",
        "\n",
        "You got images of digits and want to classify which digit appears in that image.<br/> In addition, you aim to compare different distance metric to determine which one is the best for this data."
      ],
      "metadata": {
        "id": "MsyhpIFXgWbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libaries"
      ],
      "metadata": {
        "id": "jI5R52AwqOdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IrdvlliQgXpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data, and use the internet to find our how to print one image. <br/>\n",
        "Print the image, with a plot title of its label.<br/>\n",
        "https://srworkspace.com/sharon/ml/datasets/hw1/digits.csv"
      ],
      "metadata": {
        "id": "YMt83YEaqPqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "rAGt7yWzn-pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which distance metric do you expect to work better: Euclidean distance, of the Mahalanobis distance? <br/>\n",
        "<font color='red'>Write here your answer and explain it</font>"
      ],
      "metadata": {
        "id": "685jpA45qS_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "vrb2NRL6p6gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data to 80% train and 20% test, with random state 21. <br/>\n",
        "Make sure to maintain the dataset balanced, using stratify=y, in train_test_split method. <br/> You can check the balance using df.value_counts().<br/>\n"
      ],
      "metadata": {
        "id": "4akX_fZnunkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "pzBXvhu9ukzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the functions 'Euclidian', 'Manhattan'. <br/>\n",
        "Those functions get train and test datasets ($m\\times d, n\\times d$) and returns the distance metric sized $m \\times n$, based on the distance metric.<br/>\n",
        "Reminder: Manhattan distance is $d(x,y)=\\sum_{i=1}^d |x_i-y_i|$, d is the features number.\n"
      ],
      "metadata": {
        "id": "CfUnWaYiu59l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Euclidean(test, data):\n",
        "  # Implement here\n",
        "\n",
        "def Manhattan(test, data):\n",
        "  # Implement here\n",
        "\n",
        "def Cosine(test, data):\n",
        "  # Implement here\n",
        "\n",
        "def Mahalanobis(test, data):\n",
        "  distances = np.zeros((test.shape[0], data.shape[0]))\n",
        "  covariance_matrix_data = np.cov(data, rowvar=False)\n",
        "\n",
        "  # Calculate the Mahalanobis distances\n",
        "  for i in range(test.shape[0]):\n",
        "      for j in range(data.shape[0]):\n",
        "          diff =  test[i] - data[j]\n",
        "          distances[i, j] = np.sqrt(np.dot(np.dot(diff, np.linalg.inv(covariance_matrix_data)), diff.T))\n",
        "  return distances"
      ],
      "metadata": {
        "id": "Werkv3zoztln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the function kNN_classify that returns array sized m, which are the predictions for the m test samples."
      ],
      "metadata": {
        "id": "_U-RaTeOvYOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kNN_classify(data, labels, test, k, metric='Euclidian'):\n",
        "  arguments = (test, data)\n",
        "  distances = eval(f'{metric}(*arguments)')   #returns np[][] |test| X |data| by the given metric.\n",
        "  # Implement here"
      ],
      "metadata": {
        "id": "1wvWALopvZd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the plots for different k values and compare those metrics.\n",
        "- Which metric was better? What might cause it?\n",
        "- Should the best k be selected using the test set? <br/>\n",
        "<font color='red'>Write here your answers and explain them</font>"
      ],
      "metadata": {
        "id": "oBOw9dqxwRLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = ['Manhattan', 'Euclidean']\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "\n",
        "  ks = np.arange(1, 41, 2)\n",
        "  accs = []\n",
        "  for k in ks:\n",
        "    c = kNN_classify(X_train, y_train, X_test, k, metric)\n",
        "    accs.append()   # Implement here\n",
        "\n",
        "  axs[idx % 2].plot(ks, accs, color='red')\n",
        "  axs[idx % 2].set_xlabel('k')\n",
        "  axs[idx % 2].set_ylabel('accuracy')\n",
        "  axs[idx % 2].set_title(metric)\n",
        "  axs[idx % 2].set_xticks(ks)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wp_CDXB4whVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Mahalanobis distance metric is already implemented to you. <br/>\n",
        "Run the following code and answer: ~Which gives better accuracy?<br/>~\n",
        "Edit: You will get LinAlgError: Singular matrix. Justify why it happens, looking on this specific dataset.\n",
        "\n",
        "<font color='red'>Write here your answer and explain it</font>"
      ],
      "metadata": {
        "id": "84qffnSzw8-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ks = np.arange(1, 41, 2)\n",
        "accs = []\n",
        "\n",
        "for k in ks:\n",
        "    c = kNN_classify(X_train, y_train, X_test, k, 'Mahalanobis')\n",
        "    accs.append()   # Implement here\n",
        "\n",
        "plt.plot(ks, accs)\n",
        "plt.xticks(ks)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DILox6RB0P0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, implement Cosine metric. Read about it on the internet and explain the results.<br/>\n",
        "<font color='red'>Write here your answer and explain it</font>"
      ],
      "metadata": {
        "id": "ZuA5VTinCuoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ks = np.arange(1, 41, 2)\n",
        "accs = []\n",
        "\n",
        "for k in ks:\n",
        "    c = kNN_classify(X_train, y_train, X_test, k, 'Cosine')\n",
        "    accs.append()   # Implement here\n",
        "\n",
        "plt.plot(ks, accs)\n",
        "plt.xticks(ks)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5EyqioeECuK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6 - Polynomial regression - 5 pts bonus\n",
        "In this problem you will extend regression to fit polynomial functions.<br/>\n",
        "The dataset contains one feature (x) and continiuos prediction (y)."
      ],
      "metadata": {
        "id": "2xaWiAsF0pTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "hcvqEURI1G2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load data\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "def load_npy_file(url):\n",
        "  response = requests.get(url)\n",
        "  if response.status_code == 200:\n",
        "    npy_data = np.load(BytesIO(response.content), allow_pickle=True).item()\n",
        "    return npy_data\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7djVEPUN1lmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = load_npy_file('https://sharon.srworkspace.com/ml/datasets/hw3/linreg_data_2d_new.npy')\n",
        "\n",
        "x_train = data_dict['x_train']\n",
        "y_train = data_dict['y_train']\n",
        "x_test = data_dict['x_test']\n",
        "y_test = data_dict['y_test']"
      ],
      "metadata": {
        "id": "2mAZ5cnz1qRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the plot of the training data. What do you think was the function generated the data? <br/>\n",
        "<font color='red'>Write your answer here</font>"
      ],
      "metadata": {
        "id": "YKhCv_xc51ON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_train, y_train, color='blue', s=2)\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('Generated Train')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hKxQ_WPg51is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume the polynomial regression problem of the following form:\n",
        "$$ y=a_0+a_1x+a_2x^2+...+a_dx^d $$\n",
        "The function ```get_solution``` will find the cofficients, similarly to methods done in simple linear regression. <br/>\n",
        "The function ```calc``` will recieve a new sample and the cofficients found, and will predict the output.\n",
        "\n",
        "Hint: Given the datapoint $(x,y)$ such that $y=2x^2+x-3$, we can re-write it as $y=<x^2,x,1>*<2,1,-3>$.\n",
        "\n"
      ],
      "metadata": {
        "id": "JhkNIlk915eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_solution(X, y, degree=2):\n",
        "    # Implement here\n",
        "\n",
        "def calc(x, coefs):\n",
        "    # Implement here"
      ],
      "metadata": {
        "id": "wNYVnO571y2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the current code with $d=1$ yields a simple regressor.\n",
        "- Which $d$ works best?\n",
        "- What do you expect to happen as we choose higest d's?\n",
        "\n",
        "<font color='red'>Write your answers here and explain them</font>"
      ],
      "metadata": {
        "id": "u8NvvzDE6mNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xx = np.arange(0, 100, 0.1)\n",
        "yy = []\n",
        "\n",
        "weights = get_solution(x_train, y_train, degree=1)\n",
        "\n",
        "for samp in xx:\n",
        "  yy.append(calc(samp, weights))\n",
        "\n",
        "plt.scatter(x_train, y_train, color='blue', s=2, label='train')\n",
        "plt.scatter(x_test, y_test, color='red', s=2, label='test')\n",
        "plt.plot(xx, yy, color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ON7wx4Xp6nDP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YSvfxRjjnk26",
        "GeVCGEMFSTD5",
        "prp9oMrgRud7",
        "NhrtVpKmGnzY",
        "8-sAUwri1Gwr",
        "MsyhpIFXgWbo",
        "2xaWiAsF0pTX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}